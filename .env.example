# API Keys for LLM Providers
# Copy this file to .env and fill in your keys

OPENAI_API_KEY=
ANTHROPIC_API_KEY=
GOOGLE_API_KEY=

# Ollama runs locally - no API key needed
# Start Ollama with: ollama serve
# Pull model with: ollama pull llama3
